{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data\n",
    "\n",
    "First, let's import the necessary libraries and load our training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    HistGradientBoostingClassifier,\n",
    "    StackingClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "sns.set(style=\"whitegrid\")\n",
    "np.random.seed(RANDOM_STATE)\n",
    "pd.set_option(\"display.max_columns\", 200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Now, let's explore the data to understand its structure, find patterns, and identify missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape : (891, 12)\n",
      "Test shape  : (418, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>347082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PassengerId    Survived      Pclass                     Name   Sex  \\\n",
       "count    891.000000  891.000000  891.000000                      891   891   \n",
       "unique          NaN         NaN         NaN                      891     2   \n",
       "top             NaN         NaN         NaN  Braund, Mr. Owen Harris  male   \n",
       "freq            NaN         NaN         NaN                        1   577   \n",
       "mean     446.000000    0.383838    2.308642                      NaN   NaN   \n",
       "std      257.353842    0.486592    0.836071                      NaN   NaN   \n",
       "min        1.000000    0.000000    1.000000                      NaN   NaN   \n",
       "25%      223.500000    0.000000    2.000000                      NaN   NaN   \n",
       "50%      446.000000    0.000000    3.000000                      NaN   NaN   \n",
       "75%      668.500000    1.000000    3.000000                      NaN   NaN   \n",
       "max      891.000000    1.000000    3.000000                      NaN   NaN   \n",
       "\n",
       "               Age       SibSp       Parch  Ticket        Fare    Cabin  \\\n",
       "count   714.000000  891.000000  891.000000     891  891.000000      204   \n",
       "unique         NaN         NaN         NaN     681         NaN      147   \n",
       "top            NaN         NaN         NaN  347082         NaN  B96 B98   \n",
       "freq           NaN         NaN         NaN       7         NaN        4   \n",
       "mean     29.699118    0.523008    0.381594     NaN   32.204208      NaN   \n",
       "std      14.526497    1.102743    0.806057     NaN   49.693429      NaN   \n",
       "min       0.420000    0.000000    0.000000     NaN    0.000000      NaN   \n",
       "25%      20.125000    0.000000    0.000000     NaN    7.910400      NaN   \n",
       "50%      28.000000    0.000000    0.000000     NaN   14.454200      NaN   \n",
       "75%      38.000000    1.000000    0.000000     NaN   31.000000      NaN   \n",
       "max      80.000000    8.000000    6.000000     NaN  512.329200      NaN   \n",
       "\n",
       "       Embarked  \n",
       "count       889  \n",
       "unique        3  \n",
       "top           S  \n",
       "freq        644  \n",
       "mean        NaN  \n",
       "std         NaN  \n",
       "min         NaN  \n",
       "25%         NaN  \n",
       "50%         NaN  \n",
       "75%         NaN  \n",
       "max         NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(f\"Train shape : {train_df.shape}\")\n",
    "print(f\"Test shape  : {test_df.shape}\")\n",
    "\n",
    "display(train_df.head())\n",
    "display(train_df.describe(include=\"all\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning & Feature Engineering\n",
    "\n",
    "Based on our EDA, we'll clean the data by handling missing values and create new features to improve our model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape : (891, 54)\n",
      "Test features shape  : (418, 54)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>NameLength</th>\n",
       "      <th>NameWords</th>\n",
       "      <th>HasParenthesis</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>FamilySizeSquared</th>\n",
       "      <th>TicketGroupSize</th>\n",
       "      <th>SharedTicket</th>\n",
       "      <th>FarePerPerson</th>\n",
       "      <th>FareLog</th>\n",
       "      <th>FareRank</th>\n",
       "      <th>FamilyId</th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinKnown</th>\n",
       "      <th>CabinCount</th>\n",
       "      <th>MultipleCabins</th>\n",
       "      <th>CabinNumber</th>\n",
       "      <th>CabinOdd</th>\n",
       "      <th>AgeBin</th>\n",
       "      <th>IsChild</th>\n",
       "      <th>IsTeen</th>\n",
       "      <th>IsMother</th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Fare*Class</th>\n",
       "      <th>SibSp*Parch</th>\n",
       "      <th>TicketLetters</th>\n",
       "      <th>TicketDigits</th>\n",
       "      <th>TicketLettersLen</th>\n",
       "      <th>TicketDigitsLen</th>\n",
       "      <th>TicketPrefix</th>\n",
       "      <th>TicketNumeric</th>\n",
       "      <th>SexPclass</th>\n",
       "      <th>DeckPclass</th>\n",
       "      <th>EmbarkedPclass</th>\n",
       "      <th>TitleSex</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>FamilySizeGroup</th>\n",
       "      <th>Title_survival_rate</th>\n",
       "      <th>CabinDeck_survival_rate</th>\n",
       "      <th>TicketPrefix_survival_rate</th>\n",
       "      <th>FamilyId_survival_rate</th>\n",
       "      <th>SexPclass_survival_rate</th>\n",
       "      <th>DeckPclass_survival_rate</th>\n",
       "      <th>EmbarkedPclass_survival_rate</th>\n",
       "      <th>FareBin_survival_rate</th>\n",
       "      <th>FamilySizeGroup_survival_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.62500</td>\n",
       "      <td>2.110213</td>\n",
       "      <td>0.082888</td>\n",
       "      <td>Braund_2</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>21.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>521171</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>A</td>\n",
       "      <td>521171</td>\n",
       "      <td>male_3</td>\n",
       "      <td>M_3</td>\n",
       "      <td>S_3</td>\n",
       "      <td>Mr_male</td>\n",
       "      <td>(-0.001, 7.75]</td>\n",
       "      <td>Couple</td>\n",
       "      <td>0.166690</td>\n",
       "      <td>0.305914</td>\n",
       "      <td>0.225041</td>\n",
       "      <td>0.365560</td>\n",
       "      <td>0.154837</td>\n",
       "      <td>0.242298</td>\n",
       "      <td>0.202219</td>\n",
       "      <td>0.231850</td>\n",
       "      <td>0.524843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>35.64165</td>\n",
       "      <td>4.280593</td>\n",
       "      <td>0.883499</td>\n",
       "      <td>Cumings_2</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>35-45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>PC</td>\n",
       "      <td>17599</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>PC</td>\n",
       "      <td>17599</td>\n",
       "      <td>female_1</td>\n",
       "      <td>C_1</td>\n",
       "      <td>C_1</td>\n",
       "      <td>Mrs_female</td>\n",
       "      <td>(69.55, 512.329]</td>\n",
       "      <td>Couple</td>\n",
       "      <td>0.707691</td>\n",
       "      <td>0.525406</td>\n",
       "      <td>0.564258</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.849229</td>\n",
       "      <td>0.525406</td>\n",
       "      <td>0.629742</td>\n",
       "      <td>0.660166</td>\n",
       "      <td>0.523569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.92500</td>\n",
       "      <td>2.188856</td>\n",
       "      <td>0.266616</td>\n",
       "      <td>Heikkinen_1</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25-35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>23.7750</td>\n",
       "      <td>0</td>\n",
       "      <td>STONO</td>\n",
       "      <td>23101282</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>STONO</td>\n",
       "      <td>23101282</td>\n",
       "      <td>female_3</td>\n",
       "      <td>M_3</td>\n",
       "      <td>S_3</td>\n",
       "      <td>Miss_female</td>\n",
       "      <td>(7.896, 9.844]</td>\n",
       "      <td>Solo</td>\n",
       "      <td>0.677212</td>\n",
       "      <td>0.301717</td>\n",
       "      <td>0.379910</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.523532</td>\n",
       "      <td>0.247952</td>\n",
       "      <td>0.204228</td>\n",
       "      <td>0.228489</td>\n",
       "      <td>0.303450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26.55000</td>\n",
       "      <td>3.990834</td>\n",
       "      <td>0.834607</td>\n",
       "      <td>Futrelle_2</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>35-45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>113803</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>NONE</td>\n",
       "      <td>113803</td>\n",
       "      <td>female_1</td>\n",
       "      <td>C_1</td>\n",
       "      <td>S_1</td>\n",
       "      <td>Mrs_female</td>\n",
       "      <td>(31.275, 69.55]</td>\n",
       "      <td>Couple</td>\n",
       "      <td>0.731264</td>\n",
       "      <td>0.537177</td>\n",
       "      <td>0.390370</td>\n",
       "      <td>0.365560</td>\n",
       "      <td>0.833443</td>\n",
       "      <td>0.537177</td>\n",
       "      <td>0.566478</td>\n",
       "      <td>0.450711</td>\n",
       "      <td>0.543194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.05000</td>\n",
       "      <td>2.202765</td>\n",
       "      <td>0.299465</td>\n",
       "      <td>Allen_1</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35-45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>373450</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>NONE</td>\n",
       "      <td>373450</td>\n",
       "      <td>male_3</td>\n",
       "      <td>M_3</td>\n",
       "      <td>S_3</td>\n",
       "      <td>Mr_male</td>\n",
       "      <td>(7.896, 9.844]</td>\n",
       "      <td>Solo</td>\n",
       "      <td>0.169720</td>\n",
       "      <td>0.305914</td>\n",
       "      <td>0.375765</td>\n",
       "      <td>0.413179</td>\n",
       "      <td>0.155589</td>\n",
       "      <td>0.246757</td>\n",
       "      <td>0.207539</td>\n",
       "      <td>0.232800</td>\n",
       "      <td>0.305948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked Title  NameLength  \\\n",
       "0       3    male  22.0      1      0   7.2500        S    Mr          23   \n",
       "1       1  female  38.0      1      0  71.2833        C   Mrs          51   \n",
       "2       3  female  26.0      0      0   7.9250        S  Miss          22   \n",
       "3       1  female  35.0      1      0  53.1000        S   Mrs          44   \n",
       "4       3    male  35.0      0      0   8.0500        S    Mr          24   \n",
       "\n",
       "   NameWords  HasParenthesis  FamilySize  IsAlone  FamilySizeSquared  \\\n",
       "0          4               0           2        0                  4   \n",
       "1          7               1           2        0                  4   \n",
       "2          3               0           1        1                  1   \n",
       "3          7               1           2        0                  4   \n",
       "4          4               0           1        1                  1   \n",
       "\n",
       "   TicketGroupSize  SharedTicket  FarePerPerson   FareLog  FareRank  \\\n",
       "0                1             0        3.62500  2.110213  0.082888   \n",
       "1                2             1       35.64165  4.280593  0.883499   \n",
       "2                1             0        7.92500  2.188856  0.266616   \n",
       "3                2             1       26.55000  3.990834  0.834607   \n",
       "4                1             0        8.05000  2.202765  0.299465   \n",
       "\n",
       "      FamilyId CabinDeck  CabinKnown  CabinCount  MultipleCabins  CabinNumber  \\\n",
       "0     Braund_2         M           0           0               0            0   \n",
       "1    Cumings_2         C           1           1               0           85   \n",
       "2  Heikkinen_1         M           0           0               0            0   \n",
       "3   Futrelle_2         C           1           1               0          123   \n",
       "4      Allen_1         M           0           0               0            0   \n",
       "\n",
       "   CabinOdd AgeBin  IsChild  IsTeen  IsMother  Age*Class  Fare*Class  \\\n",
       "0         0  18-25        0       0         0       66.0     21.7500   \n",
       "1         1  35-45        0       0         0       38.0     71.2833   \n",
       "2         0  25-35        0       0         0       78.0     23.7750   \n",
       "3         1  35-45        0       0         0       35.0     53.1000   \n",
       "4         0  35-45        0       0         0      105.0     24.1500   \n",
       "\n",
       "   SibSp*Parch TicketLetters TicketDigits  TicketLettersLen  TicketDigitsLen  \\\n",
       "0            0             A       521171                 1                6   \n",
       "1            0            PC        17599                 2                5   \n",
       "2            0         STONO     23101282                 5                8   \n",
       "3            0          NONE       113803                 4                6   \n",
       "4            0          NONE       373450                 4                6   \n",
       "\n",
       "  TicketPrefix  TicketNumeric SexPclass DeckPclass EmbarkedPclass  \\\n",
       "0            A         521171    male_3        M_3            S_3   \n",
       "1           PC          17599  female_1        C_1            C_1   \n",
       "2        STONO       23101282  female_3        M_3            S_3   \n",
       "3         NONE         113803  female_1        C_1            S_1   \n",
       "4         NONE         373450    male_3        M_3            S_3   \n",
       "\n",
       "      TitleSex           FareBin FamilySizeGroup  Title_survival_rate  \\\n",
       "0      Mr_male    (-0.001, 7.75]          Couple             0.166690   \n",
       "1   Mrs_female  (69.55, 512.329]          Couple             0.707691   \n",
       "2  Miss_female    (7.896, 9.844]            Solo             0.677212   \n",
       "3   Mrs_female   (31.275, 69.55]          Couple             0.731264   \n",
       "4      Mr_male    (7.896, 9.844]            Solo             0.169720   \n",
       "\n",
       "   CabinDeck_survival_rate  TicketPrefix_survival_rate  \\\n",
       "0                 0.305914                    0.225041   \n",
       "1                 0.525406                    0.564258   \n",
       "2                 0.301717                    0.379910   \n",
       "3                 0.537177                    0.390370   \n",
       "4                 0.305914                    0.375765   \n",
       "\n",
       "   FamilyId_survival_rate  SexPclass_survival_rate  DeckPclass_survival_rate  \\\n",
       "0                0.365560                 0.154837                  0.242298   \n",
       "1                0.383838                 0.849229                  0.525406   \n",
       "2                0.383838                 0.523532                  0.247952   \n",
       "3                0.365560                 0.833443                  0.537177   \n",
       "4                0.413179                 0.155589                  0.246757   \n",
       "\n",
       "   EmbarkedPclass_survival_rate  FareBin_survival_rate  \\\n",
       "0                      0.202219               0.231850   \n",
       "1                      0.629742               0.660166   \n",
       "2                      0.204228               0.228489   \n",
       "3                      0.566478               0.450711   \n",
       "4                      0.207539               0.232800   \n",
       "\n",
       "   FamilySizeGroup_survival_rate  \n",
       "0                       0.524843  \n",
       "1                       0.523569  \n",
       "2                       0.303450  \n",
       "3                       0.543194  \n",
       "4                       0.305948  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def engineer_datasets(train_df: pd.DataFrame, test_df: pd.DataFrame):\n",
    "    train = train_df.copy()\n",
    "    test = test_df.copy()\n",
    "\n",
    "    y = train[\"Survived\"].astype(int)\n",
    "    train_features = train.drop(columns=[\"Survived\"])\n",
    "    test_features = test.copy()\n",
    "    full = pd.concat([train_features, test_features], axis=0, ignore_index=True)\n",
    "\n",
    "    full[\"Title\"] = full[\"Name\"].str.extract(r\" ([A-Za-z]+)\\.\").fillna(\"Unknown\")\n",
    "    title_mapping = {\n",
    "        \"Mr\": \"Mr\", \"Mrs\": \"Mrs\", \"Miss\": \"Miss\", \"Master\": \"Master\",\n",
    "        \"Ms\": \"Miss\", \"Mlle\": \"Miss\", \"Mme\": \"Mrs\",\n",
    "        \"Lady\": \"Rare\", \"Countess\": \"Rare\", \"Capt\": \"Rare\", \"Col\": \"Rare\",\n",
    "        \"Don\": \"Rare\", \"Dr\": \"Rare\", \"Major\": \"Rare\", \"Rev\": \"Rare\",\n",
    "        \"Sir\": \"Rare\", \"Jonkheer\": \"Rare\", \"Dona\": \"Rare\"\n",
    "    }\n",
    "    full[\"Title\"] = full[\"Title\"].map(lambda t: title_mapping.get(t, \"Rare\"))\n",
    "\n",
    "    full[\"NameLength\"] = full[\"Name\"].str.len()\n",
    "    full[\"NameWords\"] = full[\"Name\"].str.split().map(len)\n",
    "    full[\"HasParenthesis\"] = full[\"Name\"].str.contains(r\"\\(\", regex=True).astype(int)\n",
    "\n",
    "    full[\"Embarked\"] = full[\"Embarked\"].fillna(full[\"Embarked\"].mode()[0])\n",
    "\n",
    "    full[\"Fare\"] = full[\"Fare\"].astype(float)\n",
    "    fare_by_class = full.groupby(\"Pclass\")[\"Fare\"].transform(\"median\")\n",
    "    full[\"Fare\"] = full[\"Fare\"].fillna(fare_by_class).fillna(full[\"Fare\"].median())\n",
    "\n",
    "    full[\"FamilySize\"] = full[\"SibSp\"] + full[\"Parch\"] + 1\n",
    "    full[\"IsAlone\"] = (full[\"FamilySize\"] == 1).astype(int)\n",
    "    full[\"FamilySizeSquared\"] = full[\"FamilySize\"] ** 2\n",
    "\n",
    "    full[\"TicketGroupSize\"] = full.groupby(\"Ticket\")[\"Ticket\"].transform(\"count\")\n",
    "    full[\"SharedTicket\"] = (full[\"TicketGroupSize\"] > 1).astype(int)\n",
    "\n",
    "    fare_per_person = (full[\"Fare\"] / np.maximum(full[\"FamilySize\"], 1)).replace([np.inf, -np.inf], np.nan)\n",
    "    full[\"FarePerPerson\"] = fare_per_person.fillna(fare_per_person.median())\n",
    "    full[\"FareLog\"] = np.log1p(full[\"Fare\"])\n",
    "    full[\"FareRank\"] = full[\"Fare\"].rank(pct=True)\n",
    "\n",
    "    full[\"LastName\"] = full[\"Name\"].str.split(\",\").str[0].str.strip()\n",
    "    full[\"FamilyId\"] = full[\"LastName\"] + \"_\" + full[\"FamilySize\"].astype(str)\n",
    "\n",
    "    full[\"CabinDeck\"] = full[\"Cabin\"].str[0].fillna(\"M\")\n",
    "    full[\"CabinKnown\"] = full[\"Cabin\"].notna().astype(int)\n",
    "    full[\"CabinCount\"] = full[\"Cabin\"].fillna(\"\").str.split().map(len)\n",
    "    full[\"MultipleCabins\"] = (full[\"CabinCount\"] > 1).astype(int)\n",
    "    full[\"CabinNumber\"] = (\n",
    "        full[\"Cabin\"]\n",
    "        .str.extract(r\"(\\d+)\")\n",
    "        .fillna(\"0\")\n",
    "        .astype(int)\n",
    "    )\n",
    "    full[\"CabinOdd\"] = (full[\"CabinNumber\"] % 2 == 1).astype(int)\n",
    "\n",
    "    age_group_med = full.groupby([\"Title\", \"Pclass\"])[\"Age\"].transform(\"median\")\n",
    "    full[\"Age\"] = full[\"Age\"].fillna(age_group_med).fillna(full[\"Age\"].median())\n",
    "\n",
    "    age_bins = [0, 12, 18, 25, 35, 45, 55, 65, np.inf]\n",
    "    age_labels = [\"0-12\", \"12-18\", \"18-25\", \"25-35\", \"35-45\", \"45-55\", \"55-65\", \"65+\"]\n",
    "    age_bin = pd.cut(full[\"Age\"], bins=age_bins, labels=age_labels, right=False)\n",
    "    full[\"AgeBin\"] = age_bin.astype(str).replace(\"nan\", \"Missing\")\n",
    "\n",
    "    full[\"IsChild\"] = (full[\"Age\"] < 12).astype(int)\n",
    "    full[\"IsTeen\"] = ((full[\"Age\"] >= 12) & (full[\"Age\"] < 18)).astype(int)\n",
    "    full[\"IsMother\"] = (\n",
    "        (full[\"Sex\"] == \"female\")\n",
    "        & (full[\"Parch\"] > 0)\n",
    "        & (full[\"Age\"] >= 18)\n",
    "        & (full[\"Title\"] == \"Mrs\")\n",
    "    ).astype(int)\n",
    "    full[\"Age*Class\"] = full[\"Age\"] * full[\"Pclass\"]\n",
    "    full[\"Fare*Class\"] = full[\"Fare\"] * full[\"Pclass\"]\n",
    "    full[\"SibSp*Parch\"] = full[\"SibSp\"] * full[\"Parch\"]\n",
    "\n",
    "    full[\"TicketLetters\"] = full[\"Ticket\"].str.replace(\"[^A-Za-z]\", \"\", regex=True).str.upper().replace(\"\", \"NONE\")\n",
    "    full[\"TicketDigits\"] = full[\"Ticket\"].str.replace(\"[^0-9]\", \"\", regex=True).replace(\"\", \"0\")\n",
    "    full[\"TicketLettersLen\"] = full[\"TicketLetters\"].str.len()\n",
    "    full[\"TicketDigitsLen\"] = full[\"TicketDigits\"].str.len()\n",
    "    full[\"TicketPrefix\"] = full[\"TicketLetters\"]\n",
    "    full[\"TicketNumeric\"] = full[\"TicketDigits\"].astype(int)\n",
    "\n",
    "    full[\"SexPclass\"] = full[\"Sex\"] + \"_\" + full[\"Pclass\"].astype(str)\n",
    "    full[\"DeckPclass\"] = full[\"CabinDeck\"] + \"_\" + full[\"Pclass\"].astype(str)\n",
    "    full[\"EmbarkedPclass\"] = full[\"Embarked\"] + \"_\" + full[\"Pclass\"].astype(str)\n",
    "    full[\"TitleSex\"] = full[\"Title\"] + \"_\" + full[\"Sex\"]\n",
    "\n",
    "    fare_bins = pd.qcut(full[\"Fare\"], q=8, duplicates=\"drop\")\n",
    "    full[\"FareBin\"] = fare_bins.astype(str).replace(\"nan\", \"Missing\")\n",
    "\n",
    "    family_size_group = pd.cut(\n",
    "        full[\"FamilySize\"],\n",
    "        bins=[0, 1, 2, 4, 7, np.inf],\n",
    "        labels=[\"Solo\", \"Couple\", \"Small\", \"Medium\", \"Large\"],\n",
    "        right=True\n",
    "    )\n",
    "    full[\"FamilySizeGroup\"] = family_size_group.astype(str).replace(\"nan\", \"Unknown\")\n",
    "\n",
    "    train_engineered = full.iloc[: len(train)].reset_index(drop=True)\n",
    "    test_engineered = full.iloc[len(train):].reset_index(drop=True)\n",
    "    train_engineered[\"Survived\"] = y.values\n",
    "\n",
    "    def add_target_rate(train_df, test_df, column, smoothing=18, n_splits=5):\n",
    "        prior = train_df[\"Survived\"].mean()\n",
    "        feature_name = f\"{column}_survival_rate\"\n",
    "        encoded = pd.Series(prior, index=train_df.index, dtype=float)\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "        for tr_idx, val_idx in skf.split(train_df, train_df[\"Survived\"]):\n",
    "            fold = train_df.iloc[tr_idx]\n",
    "            stats = fold.groupby(column)[\"Survived\"].agg([\"mean\", \"count\"])\n",
    "            smooth = (stats[\"mean\"] * stats[\"count\"] + prior * smoothing) / (stats[\"count\"] + smoothing)\n",
    "            encoded.iloc[val_idx] = train_df.iloc[val_idx][column].map(smooth).fillna(prior)\n",
    "\n",
    "        train_df[feature_name] = encoded\n",
    "        stats_full = train_df.groupby(column)[\"Survived\"].agg([\"mean\", \"count\"])\n",
    "        smooth_full = (stats_full[\"mean\"] * stats_full[\"count\"] + prior * smoothing) / (stats_full[\"count\"] + smoothing)\n",
    "        test_df[feature_name] = test_df[column].map(smooth_full).fillna(prior)\n",
    "\n",
    "    for col in [\n",
    "        \"Title\", \"CabinDeck\", \"TicketPrefix\", \"FamilyId\",\n",
    "        \"SexPclass\", \"DeckPclass\", \"EmbarkedPclass\", \"FareBin\", \"FamilySizeGroup\"\n",
    "    ]:\n",
    "        add_target_rate(train_engineered, test_engineered, col, smoothing=20)\n",
    "\n",
    "    binary_cols = [\"CabinKnown\", \"IsAlone\", \"SharedTicket\", \"IsChild\", \"IsTeen\", \"IsMother\", \"MultipleCabins\", \"HasParenthesis\", \"CabinOdd\"]\n",
    "    for col in binary_cols:\n",
    "        train_engineered[col] = train_engineered[col].astype(int)\n",
    "        test_engineered[col] = test_engineered[col].astype(int)\n",
    "\n",
    "    passenger_ids = test_engineered[\"PassengerId\"].astype(int).copy()\n",
    "\n",
    "    drop_cols = [\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\", \"LastName\"]\n",
    "    train_engineered = train_engineered.drop(columns=drop_cols)\n",
    "    test_engineered = test_engineered.drop(columns=drop_cols)\n",
    "\n",
    "    y_final = train_engineered[\"Survived\"].astype(int)\n",
    "    train_engineered = train_engineered.drop(columns=[\"Survived\"])\n",
    "\n",
    "    return train_engineered, test_engineered, y_final, passenger_ids\n",
    "\n",
    "X_train, X_test, y, passenger_ids = engineer_datasets(train_df, test_df)\n",
    "print(f\"Train features shape : {X_train.shape}\")\n",
    "print(f\"Test features shape  : {X_test.shape}\")\n",
    "display(X_train.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training and Evaluation\n",
    "\n",
    "It's time to choose a model, train it on our processed data, and see how well it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 01 accuracies -> stacking: 0.8889 | hist_gb: 0.9111 | grad_boost: 0.8778 | rand_forest: 0.8889\n",
      "Fold 02 accuracies -> stacking: 0.8090 | hist_gb: 0.7978 | grad_boost: 0.8090 | rand_forest: 0.8090\n",
      "Fold 03 accuracies -> stacking: 0.8202 | hist_gb: 0.8652 | grad_boost: 0.8652 | rand_forest: 0.8315\n",
      "Fold 04 accuracies -> stacking: 0.8315 | hist_gb: 0.8315 | grad_boost: 0.8652 | rand_forest: 0.8427\n",
      "Fold 05 accuracies -> stacking: 0.7978 | hist_gb: 0.7865 | grad_boost: 0.7865 | rand_forest: 0.8090\n",
      "Fold 06 accuracies -> stacking: 0.7978 | hist_gb: 0.8427 | grad_boost: 0.8539 | rand_forest: 0.8427\n",
      "Fold 07 accuracies -> stacking: 0.8315 | hist_gb: 0.8427 | grad_boost: 0.8539 | rand_forest: 0.8652\n",
      "Fold 08 accuracies -> stacking: 0.8202 | hist_gb: 0.8202 | grad_boost: 0.8427 | rand_forest: 0.8315\n",
      "Fold 09 accuracies -> stacking: 0.8427 | hist_gb: 0.8202 | grad_boost: 0.8315 | rand_forest: 0.8539\n",
      "Fold 10 accuracies -> stacking: 0.8315 | hist_gb: 0.8427 | grad_boost: 0.8539 | rand_forest: 0.8315\n",
      "\n",
      "Meta-logistic CV accuracy (threshold 0.50) : 0.84397 ± 0.02231\n",
      "Meta-logistic OOF accuracy (optimal threshold 0.565) : 0.85522\n",
      "\n",
      "Accuracy moyenne par modèle de base (seuil 0.50) :\n",
      "  stacking     -> 0.82709\n",
      "  hist_gb      -> 0.83605\n",
      "  grad_boost   -> 0.84396\n",
      "  rand_forest  -> 0.84057\n"
     ]
    }
   ],
   "source": [
    "\n",
    "numeric_features = X_train.select_dtypes(include=[\"int64\", \"float64\", \"int32\", \"float32\"]).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(transformers=[\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat\", categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "stacking_base_estimators = [\n",
    "    (\"rf\", RandomForestClassifier(\n",
    "        n_estimators=600,\n",
    "        max_depth=None,\n",
    "        min_samples_leaf=2,\n",
    "        max_features=\"sqrt\",\n",
    "        bootstrap=True,\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE\n",
    "    )),\n",
    "    (\"et\", ExtraTreesClassifier(\n",
    "        n_estimators=850,\n",
    "        max_depth=None,\n",
    "        min_samples_leaf=1,\n",
    "        max_features=\"sqrt\",\n",
    "        bootstrap=False,\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE\n",
    "    )),\n",
    "    (\"gb\", GradientBoostingClassifier(\n",
    "        n_estimators=420,\n",
    "        learning_rate=0.045,\n",
    "        max_depth=3,\n",
    "        min_samples_leaf=18,\n",
    "        subsample=0.9,\n",
    "        random_state=RANDOM_STATE\n",
    "    ))\n",
    "]\n",
    "\n",
    "stacking_final_estimator = LogisticRegression(\n",
    "    C=0.7,\n",
    "    penalty=\"l2\",\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=1500,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=stacking_base_estimators,\n",
    "    final_estimator=stacking_final_estimator,\n",
    "    stack_method=\"predict_proba\",\n",
    "    passthrough=True,\n",
    "    n_jobs=-1,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    ")\n",
    "\n",
    "stacking_pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", stacking_clf)\n",
    "])\n",
    "\n",
    "hist_gb_pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", HistGradientBoostingClassifier(\n",
    "        learning_rate=0.07,\n",
    "        max_depth=4,\n",
    "        max_iter=400,\n",
    "        min_samples_leaf=16,\n",
    "        l2_regularization=0.015,\n",
    "        max_bins=255,\n",
    "        random_state=RANDOM_STATE\n",
    "    ))\n",
    "])\n",
    "\n",
    "gradient_boost_pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", GradientBoostingClassifier(\n",
    "        n_estimators=480,\n",
    "        learning_rate=0.055,\n",
    "        max_depth=3,\n",
    "        min_samples_leaf=14,\n",
    "        subsample=0.95,\n",
    "        random_state=RANDOM_STATE\n",
    "    ))\n",
    "])\n",
    "\n",
    "random_forest_pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", RandomForestClassifier(\n",
    "        n_estimators=900,\n",
    "        max_depth=None,\n",
    "        min_samples_leaf=2,\n",
    "        max_features=\"sqrt\",\n",
    "        bootstrap=True,\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE\n",
    "    ))\n",
    "])\n",
    "\n",
    "base_models = {\n",
    "    \"stacking\": stacking_pipeline,\n",
    "    \"hist_gb\": hist_gb_pipeline,\n",
    "    \"grad_boost\": gradient_boost_pipeline,\n",
    "    \"rand_forest\": random_forest_pipeline\n",
    "}\n",
    "base_model_names = list(base_models.keys())\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=RANDOM_STATE)\n",
    "oof_predictions = {name: np.zeros(len(X_train), dtype=float) for name in base_model_names}\n",
    "test_predictions_cvmean = {name: np.zeros(len(X_test), dtype=float) for name in base_model_names}\n",
    "base_fold_acc = {name: [] for name in base_model_names}\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X_train, y), start=1):\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    for name, model in base_models.items():\n",
    "        estimator = clone(model)\n",
    "        estimator.fit(X_tr, y_tr)\n",
    "\n",
    "        val_proba = estimator.predict_proba(X_val)[:, 1]\n",
    "        oof_predictions[name][val_idx] = val_proba\n",
    "        test_predictions_cvmean[name] += estimator.predict_proba(X_test)[:, 1] / cv.n_splits\n",
    "\n",
    "        val_pred_binary = (val_proba >= 0.5).astype(int)\n",
    "        base_fold_acc[name].append(accuracy_score(y_val, val_pred_binary))\n",
    "\n",
    "    fold_msg = \" | \".join(\n",
    "        f\"{name}: {base_fold_acc[name][-1]:.4f}\"\n",
    "        for name in base_model_names\n",
    "    )\n",
    "    print(f\"Fold {fold:02d} accuracies -> {fold_msg}\")\n",
    "\n",
    "meta_feature_names = [f\"{name}_proba\" for name in base_model_names]\n",
    "meta_X = np.column_stack([oof_predictions[name] for name in base_model_names])\n",
    "meta_X_df = pd.DataFrame(meta_X, columns=meta_feature_names)\n",
    "\n",
    "meta_model_base = LogisticRegression(\n",
    "    C=0.9,\n",
    "    penalty=\"l2\",\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=2000,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "logistic_cv_scores = cross_val_score(meta_model_base, meta_X_df, y, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
    "print(f\"\\nMeta-logistic CV accuracy (threshold 0.50) : {logistic_cv_scores.mean():.5f} ± {logistic_cv_scores.std():.5f}\")\n",
    "\n",
    "logistic_oof = np.zeros(len(X_train), dtype=float)\n",
    "for train_idx, val_idx in cv.split(meta_X_df, y):\n",
    "    estimator = clone(meta_model_base)\n",
    "    estimator.fit(meta_X_df.iloc[train_idx], y.iloc[train_idx])\n",
    "    logistic_oof[val_idx] = estimator.predict_proba(meta_X_df.iloc[val_idx])[:, 1]\n",
    "\n",
    "threshold_grid = np.linspace(0.35, 0.65, 61)\n",
    "best_threshold, best_acc = 0.50, 0.0\n",
    "for thr in threshold_grid:\n",
    "    acc = ( (logistic_oof >= thr).astype(int) == y.values ).mean()\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_threshold = thr\n",
    "\n",
    "print(f\"Meta-logistic OOF accuracy (optimal threshold {best_threshold:.3f}) : {best_acc:.5f}\")\n",
    "\n",
    "print(\"\\nAccuracy moyenne par modèle de base (seuil 0.50) :\")\n",
    "for name in base_model_names:\n",
    "    print(f\"  {name:<12} -> {np.mean(base_fold_acc[name]):.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Submission File\n",
    "\n",
    "Finally, we'll use our trained model to make predictions on the test set and generate the submission file in the required format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy sur l'ensemble d'entraînement (ré-entraînement complet, seuil 0.565) : 0.94725\n",
      "✅ Fichier 'submission.csv' généré avec succès.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Poids du méta-modèle (influence de chaque base) :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rand_forest_proba    2.450650\n",
       "grad_boost_proba     2.111053\n",
       "stacking_proba       1.279295\n",
       "hist_gb_proba       -0.036341\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aperçu des probabilités (moyennes CV vs finale) :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stacking_cv_mean</th>\n",
       "      <th>hist_gb_cv_mean</th>\n",
       "      <th>grad_boost_cv_mean</th>\n",
       "      <th>rand_forest_cv_mean</th>\n",
       "      <th>meta_proba_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.403472</td>\n",
       "      <td>0.065109</td>\n",
       "      <td>0.136784</td>\n",
       "      <td>0.137821</td>\n",
       "      <td>0.163146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.254312</td>\n",
       "      <td>0.044014</td>\n",
       "      <td>0.155130</td>\n",
       "      <td>0.463287</td>\n",
       "      <td>0.248203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.033346</td>\n",
       "      <td>0.057286</td>\n",
       "      <td>0.051664</td>\n",
       "      <td>0.148653</td>\n",
       "      <td>0.096046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.075851</td>\n",
       "      <td>0.273202</td>\n",
       "      <td>0.184718</td>\n",
       "      <td>0.120745</td>\n",
       "      <td>0.121070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.578056</td>\n",
       "      <td>0.917643</td>\n",
       "      <td>0.869778</td>\n",
       "      <td>0.553879</td>\n",
       "      <td>0.775073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stacking_cv_mean  hist_gb_cv_mean  grad_boost_cv_mean  rand_forest_cv_mean  \\\n",
       "0          0.403472         0.065109            0.136784             0.137821   \n",
       "1          0.254312         0.044014            0.155130             0.463287   \n",
       "2          0.033346         0.057286            0.051664             0.148653   \n",
       "3          0.075851         0.273202            0.184718             0.120745   \n",
       "4          0.578056         0.917643            0.869778             0.553879   \n",
       "\n",
       "   meta_proba_final  \n",
       "0          0.163146  \n",
       "1          0.248203  \n",
       "2          0.096046  \n",
       "3          0.121070  \n",
       "4          0.775073  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prêt pour une nouvelle soumission Kaggle 🚀\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "meta_model_final = clone(meta_model_base)\n",
    "meta_model_final.fit(meta_X_df, y)\n",
    "\n",
    "fitted_base_models = {}\n",
    "train_meta_full = []\n",
    "test_meta_full = []\n",
    "\n",
    "for name, model in base_models.items():\n",
    "    estimator = clone(model)\n",
    "    estimator.fit(X_train, y)\n",
    "    fitted_base_models[name] = estimator\n",
    "\n",
    "    train_meta_full.append(estimator.predict_proba(X_train)[:, 1])\n",
    "    test_meta_full.append(estimator.predict_proba(X_test)[:, 1])\n",
    "\n",
    "train_meta_matrix = np.column_stack(train_meta_full)\n",
    "test_meta_matrix = np.column_stack(test_meta_full)\n",
    "\n",
    "train_meta_df = pd.DataFrame(train_meta_matrix, columns=meta_feature_names)\n",
    "test_meta_df = pd.DataFrame(test_meta_matrix, columns=meta_feature_names)\n",
    "\n",
    "train_meta_proba = meta_model_final.predict_proba(train_meta_df)[:, 1]\n",
    "train_meta_pred = (train_meta_proba >= best_threshold).astype(int)\n",
    "train_meta_accuracy = (train_meta_pred == y.values).mean()\n",
    "print(f\"Accuracy sur l'ensemble d'entraînement (ré-entraînement complet, seuil {best_threshold:.3f}) : {train_meta_accuracy:.5f}\")\n",
    "\n",
    "test_meta_proba = meta_model_final.predict_proba(test_meta_df)[:, 1]\n",
    "test_predictions = (test_meta_proba >= best_threshold).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": passenger_ids,\n",
    "    \"Survived\": test_predictions\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"✅ Fichier 'submission.csv' généré avec succès.\")\n",
    "display(submission.head())\n",
    "\n",
    "meta_coefficients = pd.Series(meta_model_final.coef_.ravel(), index=meta_feature_names).sort_values(ascending=False)\n",
    "print(\"\\nPoids du méta-modèle (influence de chaque base) :\")\n",
    "display(meta_coefficients)\n",
    "\n",
    "ensemble_preview = pd.DataFrame({\n",
    "    \"stacking_cv_mean\": test_predictions_cvmean[\"stacking\"],\n",
    "    \"hist_gb_cv_mean\": test_predictions_cvmean[\"hist_gb\"],\n",
    "    \"grad_boost_cv_mean\": test_predictions_cvmean[\"grad_boost\"],\n",
    "    \"rand_forest_cv_mean\": test_predictions_cvmean[\"rand_forest\"],\n",
    "    \"meta_proba_final\": test_meta_proba\n",
    "}).head()\n",
    "print(\"\\nAperçu des probabilités (moyennes CV vs finale) :\")\n",
    "display(ensemble_preview)\n",
    "\n",
    "print(\"Prêt pour une nouvelle soumission Kaggle 🚀\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
